---
title: "191111"
output: html_notebook
---

# Chapter 14 Random variables
How to mathematically describe random variables?


## 14.1 Random variables
Random variables are numeric outcomes resulting from random processes. 

Define `X` to be 1 if a bead is blue and red otherwise:
```{r}
beads <- rep( c("red", "blue"), times = c(2,3))
X <- ifelse(sample(beads, 1) == "blue", 1, 0)
```

Here X is a random variable: every time we select a new bead the outcome changes randomly. See below:
```{r}
ifelse(sample(beads, 1) == "blue", 1, 0)
```
Sometimes it’s 1 and sometimes it’s 0.

## 14.2 Sampleing models
We will assume that 1,000 people will play and that the only game you can play on the roulette wheel is to bet on red or black. 
= to predict how much money they will make or lose. 
= range of values, what’s the chance of losing money

Define a random variable $S$: casino’s total winnings. 

A roulette wheel has 18 red pockets, 18 black pockets and 2 green ones. (=urn)
So playing a color in one game of roulette is equivalent to drawing from this urn:
```{r}
color <- rep(c("Black", "Red", "Green"), c(18, 18, 2))
```
The 1,000 outcomes from 1,000 people playing are independent draws from this urn. 

If **red** comes up, the gambler wins & casino loses a dollar = -$1. 
Otherwise, the casino wins a dollar = $1. 

To construct our random variable `S`, we can use this code:
```{r}
n <- 1000
X <- sample(ifelse(color == "Red", -1, 1),  n, replace = TRUE)
X[1:10]
```

Because we know the proportions of 1s and -1s, we can generate the draws with one line of code, without defining color:
```{r}
X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
```

-> sampling model 

The total winnings $S$ is simply the sum of these 1,000 independent draws:
```{r}
X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
S <- sum(X)
S
```

## 14.3 The probability distribution of a random variable
S changes everyy time b= random variable

the probability of the observed value falling at any given interval.
= the probability that we lose money 
-> the probability that $S$ is in the interval $S<0$.

if we can define a cumulative distribution function $F(a) = Pr(S≤a)$,
=> can know the probability of events defined by our random variable S

F = random variable's distribution funtion

We can estimate the distribution function for the random variable  
$S$ by using a Monte Carlo simulation to generate many realizations of the random variable. 

With this code, we run the experiment of having 1,000 people play roulette, over and over, specifically $B = 10000$ times:
```{r}
n <- 1000
B <- 10000
roulette_winnings <- function(n){
  X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S <- replicate(B, roulette_winnings(n)) # 반복하는 작업
```

Now we can ask the following: in our simulations, how often did we get sums less than or equal to `a`?
```{r}
mean(S <= a)
```
= approximation of F(a)

how likely is it that we will lose money? We can see it is quite low:
```{r}
mean(S<0)
```

We can visualize the distribution of S by creating a histogram showing the probability $F(b)- F(a)$ for several intervals (a,b]:
```{r}
hist(S)
```
The distribution appears to be approximately normal.
= all we need to define the distribution is the `average` and the `standard deviation`. Because we have the original values from which the distribution is created, we can easily compute these with `mean(S)` and `sd(S)`.

this average = *expected value*
this standard deviation = *random variable S*

We can use the function `dbinom` and `pbinom` to compute the probabilities exactly. For example, to compute $Pr(S<0)$ we note that:
$$
 Pr(S<0) = Pr((S+n)/2 <(0+n)/2)
$$
and we can use the `pbinom` to compute 
$$
Pr(S≤0)
$$

```{r}
n <- 1000
pbinom(n/2, size = n, prob = 10/19)
```

Because this is a discrete probability function, to get $Pr(S<0)$ rather than $Pr(S≤0)$, we write:
```{r}
pbinom(n/2-1, size = n, prob = 10/19)
```

## 14.4 Distributions versus probability distributions
Distribution of a list of numbers / probability distribution
$F(a)$ =  function that tells us what proportion of the list is less than or equal to **a**
When the distribution is approximately normal, we define the average and standeard deviation. These are defined with a straightforward operation of the vector containing the list of numbers `x`:
```{r}
m <- sum(x)/length(x)
s <- sqrt(sum((x - m)^2) / length(x))
```

A random variable $X$ has a distribution function.
: do not need a list of numbers

-> define the distribution as the $F(a)$, probability is no list of numbers

if $X$ is defined by drawing from an urn with numbers in it, then there is a list: the list of numbers inside the urn.
 (average and standard deviation of that list are the expected value and standard error of the random variable)
 
## 14.5 Notation for random variables
Upper case letters: random variables 
Lower case letters: observed values

$X ≤ x$

## 14.6 The expected value and standard error
The first important concept to learn is the *expected value*. In statistics books, it is common to use letter $E$ like this:

$$
E[X]
$$
to denote the expected value of the random variable $X$.

the average of the draws will approximate the expected value (many draws)

*expected value of a random variable defined by one draw is the average of the numbers in the urn*

In the urn used to model betting on red in roulette, we have 20 one dollars and 18 negative one dollars. The expected value is thus:
$$
E[X] = 20(+-18/38)
$$
which about 5 cents.

```{r}
B <- 10^6
x <- sample(c(-1,1), B, replace = TRUE, prob=c(9/19, 10/19))
mean(x)
```

In general, if the urn has two possible outcomes, say  
a and b, with proportions p and 1−p respectively, the average is:
$$
E[X] = ap + b(1-p)
$$
There are $n$ neads in the urn, then we have $np a$s and $n(1-p)b$s and because the average is the sum, $n$ x $a$ x $p$ + $n$ x $b$ x $(1-p)$, divided by the total $n$, we get that the average is $ap$ + $b(1-p)$.

It is a bit counterintuitive to say that $X$ varies around 0.05, when the only values it takes is 1 and -1.

The first useful fact is that the expected value of the sum of the draws is:
$$
number\ of\ draws\ × average\ of\ the\ numbers\ in\ the\ urn
$$

So if 1,000 people play roulette, the casino expects to win, on average, about 1,000 ×$0.05 = $50. But this is an expected value.

The standard error (SE) gives us an idea of the size of the variation around the expected value. In statistics books, it’s common to use:
$$
SE[X]
$$
to denote the standard error of a random variable.

If our draws are **independent**, then the *standard error of the sum* is given by the equation:


$$
\sqrt{number\ of\ draws} × standard\ deviation\ of\ the\ numbers\ in\ the\ urn
$$

Using the definition of standard deviation, we can derive, with a bit of math, that if an urn contains two values $a$ and $b$ with proportions $p$ and $(1−p)$, respectively, the standard deviation is:

$$
|b-a| \sqrt{p(1-p)}
$$
So in our roulette example, the standard deviation of the values inside the urn is:
$|1-(-1)| \sqrt{10/19 ×9/19}$ or:
```{r}
2 * sqrt(90)/19
```

Standard error: typical difference between a random variable and its expectation

Using the formula above, the sum of 1,000 people playing has standard error of about $32:
```{r}
n <- 1000
sqrt(n) * 2 * sqrt(90)/19
```
As a result, when 1,000 people bet on red, the casino is expected to win $50 with a standard error of $32.

### 14.6.1 Population SD versus the sample SD
The standard deviation of a list `x` (below we use heights as an example) is defined as the square root of the average of the squared differences:
```{r}
library(dslabs)
x <- heights$height
m <- mean(x)
s <- sqrt(mean((x-m)^2))
```

Using mathematical notation we write:
$$
\mu = \frac{1}{n} \sum_{i=1}^Nx_i\\\
\sigma = \sqrt{ \frac{1}{N} \sum_{i=1}^N (x_i -\mu)^2}
$$

However, be aware that the `sd` function returns a slightly different result:
```{r}
identical(s, sd(x))
s-sd(x)
```
This is because the sd function R does not return the sd of the list, but rather uses a formula that estimates standard deviations of a population from a random sample.

Divide the sum of squares by the $N-1$.
$$
X = \frac{1}{N} \sum_{i=1}^Nx_i,\ s= \sqrt{ \frac{1}{N-1} \sum_{i=1}^N (X -X)^2}
$$

You can see that this is the case by typing:
```{r}
n <- length(x)
s-sd(x)*sqrt((n-1) / n)
```

compute the actual standard deviation as defined:
```{r}
sqrt(mean((x-m)^2))
```

This is because when the list size is big, these two are practically equivalent since $\sqrt{(N-1)/N}=1$.






