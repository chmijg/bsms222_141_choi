---
title: "20191120"
output: html_notebook
---

# Chapter 15 Statistical inference

## 15.1 poll
Polls are useful when interviewing every member of a particular population is logistically impossible.  
= choose a smaller group randomly and infer the opinions of the entire population from the opinions of the smaller group. -> inference

MoE: margin of error

### 15.1.1 The sampling model for polls
- urn (beads=voters) ,$25 dollar prize
- guess the spread between the proportion of blue and red beads in this urn (in this case, a pickle jar):

- You can take a sample (with replacement) from the urn
- costs $0.10 per each bead you sample

The dslabs package includes a function that shows a random draw from this urn:
```{r}
library(tidyverse)
library(dslabs)
take_poll(25)
```
The beads inside the urn represent the individuals that will vote on election day. 

## 15.2 Populations, samples, parameters, and estimates
We want to predict the proportion of blue beads in the urn. = $p$
the proportion of red beads = $1-p$
the spread = $p-(1-p) = 2p-1$

The beads in the urn are called the *population*.
The proportion of blue beads in the population $p$ is called a *parameter*.
The 25 beads are called a $sample$.

First, remember that the sample proportion is a random variable. If we run the command `take_poll(25)` four times, we get a different answer each time, since the sample proportion is a random variable.

### 15.2.1 The sample average
We start by defining the random variable $X$ as :$X=1$ if we pick a blue bead at random and $X=0$ if it is red. -> the population is a list of 0s and 1s.

If we sample $N$ beads, the average of the draws $X_1,...,X_N$ is equivalent to the portion of blue beads in our sample.

average = $\bar{X}$
(a bar on top of a symbol means the average.)
The theory we just learned about the sum of draws becomes useful because the average is a sum of draws multiplied by the constant $1/N$:
$$
\bar{X}=1/N×\sum_{i=1}^N X_i
$$
The draws are indepenent: we return each sampled bead to the urn.
Q. distribution of the sum of draws?
- expected value of the sum of draws is $N$ times the average of the values in the urn.
- we dont know how many of each blue and read bead is in the urn. 
-> estimate $p$.

### 15.2.2 Parameters
In statistical inference we define parameters to define unknown parts of our models. In the urn model we do not know the proportion of blue beads in the urn. We define the parameters $p$ represent this quantity.  
$p$ is the average of the urn: if we take the average of the 1s (blue) and 0s (red), we get the proportion of blue beads.

### 15.2.4 Properties of our estimate: expected value and standard error
The sample proportion: $\bar{X}$ (= sum of independent draws)

The expected value of the sum $N\bar{X}$ is $N$x the average of the urn,p.
$$
E(\bar{X}) = p
$$
The standard error of the sum: $\sqrt{N}×$the standard deviation of the urn.
= $(1-0)\sqrt{p(1-p)}=\sqrt{p(1-p)}$
We are dividing the sum by $N$, the standard error of the average:
$$
SE(\bar{X})=\sqrt{p(1-p)/N}
$$
The expected vale of the sample proportion $\bar{X}$ is the parameter of interest $p$ (standard error와 N은 반비례)

From the plot we see that we would need a poll of over 10,000 people to get the standard error that low. We rarely see polls of this size due in part to costs. From the Real Clear Politics table, we learn that the sample sizes in opinion polls range from 500-3,500 people. For a sample size of 1,000 and $p=0.51$, the standard error is:
```{r}
sqrt(p*(1-p))/sqrt(1000)
```

## 15.3 Exercises
1.Suppose you poll a population in which a proportion $p$ of voters are Democrats and $1−p$ are Republicans. Your sample size is $N=25$. Consider the random variable $S$ which is the total number of Democrats in your sample. What is the expected value of this random variable? Hint: it’s a function of $p$.
```{r}
B <- 25
S <- sample(c(1,0),B, replace = TRUE,prob=c(p,1-p))
mean(S)
25p
```
2. What is the standard error of $S$? Hint: it’s a function of $p$.
```{r}
Q <- sqrt(p*(1-p)/25)
Q
```

3. Consider the random variable $S/N$. This is equivalent to the sample average, which we have been denoting as $\bar{X}$. What is the expected value of the $\bar{X}$? Hint: it’s a function of $p$.

4. What is the standard error of $\bar{X}$? Hint: it’s a function of $p$.

5. Write a line of code that gives you the standard error `se` for the problem above for several values of $p$, specifically for `p <- seq(0, 1, length = 100)`. Make a plot of `se` versus `p`.

6. Copy the code above and put it inside a for-loop to make the plot for $N=25$, $N=100$, and $N=1000$.

7. If we are interested in the difference in proportions, $p-(1-p)$, our estimate is $d=\bar{X}-(1-\bar{X})$. Use the rules we learned about sums of random variables and scaled random variables to derive the expected value of $d$.

8. What is the standard error of $d$?

9. If the actual $p=.45$, it means the Republicans are winning by a relatively large margin since $d=-.1$, which is a 10% margin of victory. In this case, what is the standard error of $2\bar{X}-1$ if we take a sample of $N=25$?

10. Given the answer to 9, which of the following best describes your strategy of using a sample size of $N=25$?



## 15.4 Central Limit Therem in practice
Suppose we want to know what is the probability that we are within 1% from $p$. We are basically asking what is
$$
Pr(|\bar{X}-p|≤.01)
\\= Pr(|\bar{X}|≤p+.01)-Pr(|\bar{X}|≤p-.01)
$$

Subtract the expected value and divide by the standard error to get a standard normal random variable, call it $Z$. Since $p$ is the expected value and $SE(\bar{X}=\sqrt{p(1-p)/N}$ is the standard error we get:
$$
Pr(Z≤\frac{.01}{SE(\bar{X})})-Pr(Z≤-\frac{.01}{SE(\bar{X})})
$$
One problem we have is that since we don’t know $p$, we don't know $SE(\bar{X})$

We say that we plug-in the estimate. Our estimate of the standard error is therefore:
$$
SE(\bar{X})=\sqrt{\bar{X}(1-\bar{X})/N}
$$

In our first sample we had 12 blue and 13 red so $\bar{X}=0.48$ and our estimate of standard error is:
```{r}
x_hat <- 0.48
se <- sqrt(x_hat*(1-x_hat)/25)
se
```
And now we can answer the question of the probability of being close to $p$. The answer is:
```{r}
pnorm(0.01/se) - pnorm(-0.01/se)
```

Earlier we mentioned the margin of error. Now we can define it because it is simply two times the standard error, which we can now estimate. In our case it is:
```{r}
1.96*se
```

Why do we multiply by 1.96? Because if you ask what is the probability that we are within 1.96 standard errors from $p$, we get:
$$
Pr(Z≤1.96SE(\bar{X})/SE(\bar{X}))-Pr(Z≤-1.96SE(\bar{X})/SE(\bar{X}))
\\= Pr(Z≤1.96)-Pr(Z≤-1.96)
$$
which we know is about 95%:
```{r}
pnorm(1.96)-pnorm(-1.96)
```

### 15.4.1 A Monte Carlo simulation
Suppose we want to use a Monte Carlo simulation to corroborate the tools we have built using probability theory. To create the simulation, we would write code like this:
```{r}
B <- 10000
N <- 1000
x_hat <- replicate(B, {
  x <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
  mean(x)
})
```

The problem is, of course, we don’t know `p.` You could take 10,000 samples, count the beads and keep track of the proportions of blue. We can use the function `take_poll(n=1000)` instead of drawing from an actual urn, but it would still take time to count the beads and enter the results.

One thing we therefore do to corroborate theoretical results is to pick one or several values of `p` and run the simulations. Let’s set `p=0.45`. We can then simulate a poll:
```{r}
p <- 0.45
N <- 1000

x <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
x_hat <- mean(x)
```

In this particular sample, our estimate is `x_hat`. We can use that code to do a Monte Carlo simulation:
```{r}
B <- 10000
x_hat <- replicate(B, {
  x <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
  mean(x)
})
```

$\bar{X}$ is approximately normally distributed, has expected value $p=0.45$ and standard error $\sqrt{p(1-p)/N}=0.016$. The simulation confirms this: 
```{r}
mean(x_hat)
sd(x_hat)
```
A histogram and qq-plot confirm that the normal approximation is accurate as well:
```{r}
hist(x_hat)
```

### 15.4.2 The spread Bias: why nor tun a very large poll
However, because we are assuming there are only two parties, we know that the spread is $p-(1-p)=2p-1$. Once we have our estimate $\bar{X}$ and $SE(\bar{X})$, we estimate the spread with $2\bar{X}-1$ and the standard error is $2SE(\bar{X})$. 

For our 25 item sample above, our estimate $p$ is `.48` with margin of error `.20` and our estimate of the spread is `0.04` with margin of error `.40`. 

### 15.4.3 Bias: why ot run a very large poll?
For realistic values of $p$, say from 0.35 to 0.65, if we run a very large poll with 100,000 people, theory tells us that we would predict the election perfectly since the largest possible margin of error is around 0.3%:

One reason is that running such a poll is very expensive. 
Another possibly more important reason is that theory has its limitations.

## 15.5 Exercises
1. Write an urn model function that takes the proportion of Democrats $p$ and the sample size $N$ as arguments and returns the sample average if Democrats are 1s and Republicans are 0s. Call the function
`take_sample`.

2. Now assume `p <- 0.45` and that your sample size is $N=100$. Take a sample 10,000 times and save the vector of `mean(X) - p` into an object called `errors.` Hint: use the function you wrote for exercise 1 to write this in one line of code.

3. The vector errors contains, for each simulated sample, the difference between the actual $p$ and our estimate $\bar{X}$. We refer to this difference as the error. Compute the average and make a histogram of the errors generated in the Monte Carlo simulation and select which of the following best describes their distributions:
```{r}
mean(errors)
hist(errors)
```

4. The error $\bar{X}-p$ is a random variable. In practice, the error is not observed because we do not know $p$. Here we observe it because we constructed the simulation. What is the average size of the error if we define the size by taking the absolute value $∣\bar{X}−p∣$?

5. The standard error is related to the typical size of the error we make when predicting. We say size because we just saw that the errors are centered around 0, so thus the average error value is 0. For mathematical reasons related to the Central Limit Theorem, we actually use the standard deviation of `errors` rather than the average of the absolute values to quantify the typical size. What is this standard deviation of the errors?

6. The theory we just learned tells us what this standard deviation is going to be because it is the standard error of $\bar{X}$. What does theory tell us is the standard error of $\bar{X}$ for a sample size of 100?
  
7. In practice, we don’t know $p$, so we construct an estimate of the theoretical prediction based by plugging in $\bar{X}$ for $p$. Compute this estimate. Set the seed at 1 with `set.seed(1)`.

8. Note how close the standard error estimates obtained from the Monte Carlo simulation (exercise 5), the theoretical prediction (exercise 6), and the estimate of the theoretical prediction (exercise 7) are. The theory is working and it gives us a practical approach to knowing the typical error we will make if we predict  
$p$ with $\bar{X}$.  Another advantage that the theoretical result provides is that it gives an idea of how large a sample size is required to obtain the precision we need. Earlier we learned that the largest standard errors occur for $p=0.5$.Create a plot of the largest standard error for $N$ranging from 100 to 5,000. Based on this plot, how large does the sample size have to be to have a standard error of about 1%?

9. For sample size $N=100$, the central limit theorem tells us that the distribution of $\bar{X}$ is:

10. Based on the answer from exercise 8, the error $\bar{X}-p$ is:

11. To corroborate your answer to exercise 9, make a qq-plot of the errors you generated in exercise 2 to see if they follow a normal distribution.

12. If $p=0.45$ and $N=100$ as in exercise 2, use the CLT to estimate the probability that $\bar{X}>0.5$. You can assume you know $p=0.45$ for this calculation.

13. Assume you are in a practical situation and you don’t know $p$. Take a sample of size $N=100$ and obtain a sample average of $\bar{X}=0.51$.  What is the CLT approximation for the probability that your error is equal to or larger than 0.01?
