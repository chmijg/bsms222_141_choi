---
title: "20191104"
output: html_notebook
---

# Chapter 13 Probability

## 13.1 Discrete probability
The subset of probability is referred to as *discrete probability*. 

### 13.1.1 Relative frequency
For example: 2 red beads, 3 bule beads inside an urn, pick one at random
-> probability of picking a red one?
answer: 2/5 or 40% (5 outcome-two condition, the probability is .4 for red and .6 for blue)

probabilityproportion of ties the event accurs when we repeat the experiment an infinite number of times under the dame conditions

### 13.1.2 Notation
Notatio **Pr(A)** : denote the probability of event A happening.
event: things that can happen when something occurs by chance
continuous variable: use >= for range

### 13.1.3 Probability distributions
If we are randomly calling likely voters from a population that is 44% Democrat, 44% Republican, 10% undecided, and 2% Green Party, these proportions define the probability for each group. The probability distribution is:

## 13.2 Monte Carlo simulations for categorical data
First, we use the function rep to generate the urn:
```{r}
beads <- rep(c("red", "blue"), times = c(2,3))
beads
```
and then use sample to pick a bead at random:
```{r}
sample(beads,1)
```
This line of code produces one random outcome.

*Monte carlo simulation*: if we want to repeat the experiment an infinite time even is is impossible, we can repeat that a large enough number of times to make the results practically equivalent to repeating forever.

practically equivalent: how a large number of experiments getss us to what happens in the limit.

To perform our first Monte Carlo simulation, we use the `replicate` function, which permits us to repeat the same task any number of times. Here, we repeat the random event B=10,000 times:
```{r}
B <- 10000
events <- replicate(B,sample(beads,1))
```

We can now see if our definition actually is in agreement with this Monte Carlo simulation approximation. We can use `table` to see the distribution:
```{r}
tab <- table(events)
tab
```

and prop.table gives us the proportions:
```{r}
prop.table(tab)
```
The numbers above are the estimated probabilities provided by this Monte Carlo simulation. Statistical theory, not covered here, tells us that as B gets larger, the estimates get closer to 3/5=.6 and 2/5=.4.
  
### 13.2.1 Setting the random seed
Before we continue, we will briefly explain the following important line of code:
```{r}
set.seed(1986) 
```
If we want to avoid using the same seed everytime, a popular way to pick the seed is the year - month - day. 


### 13.2.2 With and without replacement
The function `sample` has an argument that permits us to pick more than one element from the urn. However, by default, this selection occurs without replacement: 
after a bead is selected, it is not put back in the bag.

Notice what happens when we ask to randomly select five beads:
```{r}
sample(beads,5)
sample(beads,5)
sample(beads,5)
```

This results in rearrangements that always have three blue and two red beads. If we ask that six beads be selected, we get an error:
```{r}
sample(beads, 6)
```

However, the `sample` function can be used directly, without the use of `replicate`, to repeat the same experiment of picking 1 out of the 5 beads, continually, under the same conditions. To do this, we sample with replacement: return the bead back to the urn after selecting it. We can tell `sample` to do this by changing the `replace` argument, which defaults to `FALSE`, to `replace = TRUE`:

```{r}
events <- sample(beads, B, replace = TRUE)
prop.table(table(events))
```
Not surprisingly, we get results very similar to those previously obtained with *replicate*.

## 13.3 Independence
We say two events are independent if the outcome of one does not affect the other.

Many examples of events that are not independent come from card games. 
: the first outcome affected the next one.

To see an extreme case of non-independent events, consider our example of drawing five beads at random without replacement:
```{r}
x <- sample(beads, 5)
```

If you have to guess the color of the first bead, you will predict blue since blue has a 60% chance. But if I show you the result of the last four outcomes:
```{r}
x[2:5]
```
 Now you know that the probability of red is 1 since the only bead left is red. The events are not independent, so the probabilities change.

## 13.4 Conditional probabilities
When events are not independent, *conditional probabilities* are useful.

In probability, we use the following notation:

We use the \(\mid\) as shorthand for “given that” or “conditional on”.

When two events, say \(A\) and \(B\), are independent, we have:

\[\mbox{Pr}(A \mid B) = \mbox{Pr}(A) \]

This is the mathematical way of saying: the fact that \(B\) happened does not affect the probability of \(A\) happening. In fact, this can be considered the mathematical definition of independence.

## 13.5 Addition and multiplication rules

### 13.5.1 Multiplication rule
If we want to know the probability of two events, say \(A\) and \(B\), occurring, we can use the multiplication rule:
\[ \mbox{Pr}(A \mbox{ and } B) = \mbox{Pr}(A)\mbox{Pr}(B \mid A) \] 

The multiplication rule also applies to more than two events. We can use induction to expand for more events:
\[ \mbox{Pr}(A \mbox{ and } B \mbox{ and } C) = \mbox{Pr}(A)\mbox{Pr}(B \mid A)\mbox{Pr}(C \mid A \mbox{ and } B) \]

### 13.5.2 Multiplication rule under independence
When we have independent events, then the multiplication rule becomes simpler:

\[ \mbox{Pr}(A \mbox{ and } B \mbox{ and } C) = \mbox{Pr}(A)\mbox{Pr}(B)\mbox{Pr}(C) \]
Be careful! assuming independence can lead to different and incorrect probability caculation

The multiplication rule also gives us a general formula for computing conditional probabilities:

\[ \mbox{Pr}(B \mid A) = \frac{\mbox{Pr}(A \mbox{ and } B)}{ \mbox{Pr}(A)} \]

### 13.5.3 Addition rule
The addition rule tells us that:

\[ \mbox{Pr}(A \mbox{ or } B) = \mbox{Pr}(A) + \mbox{Pr}(B) - \mbox{Pr}(A \mbox{ and } B) \]
= same concept with finding out the sum of probabilities in a Venn diagram

## 13.6 Combinations and permutations
To compute the probability distribution of one draw, we simply listed out all the possibilities
= for each event, we counted how many of these possibilities were associated with the event. 

For more complicated cases, the computations are not as straightforward. In a discrete probability course you learn theory on how to make these computations.

First, let’s construct a deck of cards. For this, we will use the `expand.grid` and `paste` functions. 

`paste`: to create strings by joining smaller strings
To do this, we take the number and suit of a card and create the card name like this:
```{r}
number <- "Three"
suit <- "Hearts"
paste(number, suit)
```

`paste` also works on pairs of vectors performing the operation element-wise:
```{r}
paste(letters[1:5], as.character(1:5))
```

`expand.grid`: gives us all the combinations of entries of two vectors.
For example, if you have blue and black pants and white, grey, and plaid shirts, all your combinations are:
```{r}
expand.grid(pants = c("blue", "black"), shirt = c("white", "grey", "plaid"))
```

Here is how we generate a deck of cards:
```{r}
suits <- c("Diamonds", "Clubs", "Hearts", "Spades")
numbers <- c("Ace", "Deuce", "Three", "Four", "Five", "Six", "Seven", 
             "Eight", "Nine", "Ten", "Jack", "Queen", "King")
deck <- expand.grid(number=numbers, suit=suits)
deck <- paste(deck$number, deck$suit)
```

With the deck constructed, we can double check that the probability of a King in the first card is 1/13 by computing the proportion of possible outcomes that satisfy our condition:
```{r}
kings <- paste("King", suits)
mean(deck %in% kings)
```
Now, how about the conditional probability of the second card being a King given that the first was a King? Earlier, we deduced that if one King is already out of the deck and there are 51 left, then this probability is 3/51. Let’s confirm by listing out all possible outcomes.

`permutations`: computes all the different combinations we can get when we select `r` items for any list of size `n`
= permutations(n,r)

Here are all the ways we can choose two numbers from a list consisting of `1,2,3`:
```{r}
library(gtools)
permutations(3, 2)
```
Notice that the order matters here: 3,1 is different than 1,3. Also, note that (1,1), (2,2), and (3,3) do not appear because once we pick a number, it can’t appear again.

Optionally, we can add a vector. If you want to see five random seven digit phone numbers out of all possible phone numbers (without repeats), you can type:
```{r}
all_phone_numbers <- permutations(10, 7, v = 0:9)
n <- nrow(all_phone_numbers)
index <- sample(n, 5)
all_phone_numbers[index,]
```
Instead of using the numbers 1 through 10, the default, it uses what we provided through v: the digits 0 through 9.

To compute all possible ways we can choose two cards when the order matters, we type:
```{r}
hands <- permutations(52, 2, v = deck)
head(hands)
```

This is a matrix with two columns and 2652 rows. With a matrix we can get the first and second cards like this:
```{r}
first_card <- hands[,1]
second_card <- hands[,2]
```

Now the cases for which the first hand was a King can be computed like this:
```{r}
kings <- paste("King", suits)
sum(first_card %in% kings)
```

```{r}
sum(first_card%in%kings & second_card%in%kings) / sum(first_card%in%kings)
```

which is exactly 3/51, as we had already deduced. Notice that the code above is equivalent to:
```{r}
mean(first_card%in%kings & second_card%in%kings) / mean(first_card%in%kings)
```

which uses `mean` instead of `sum` and is an R version of:

\[ \frac{\mbox{Pr}(A \mbox{ and } B)}{ \mbox{Pr}(A)} \]

If we wanted to compute the probability of this happening, we would enumerate the combinations, not the permutations, since the order does not matter.
```{r}
combinations(3,2)
```

In the second line, the outcome does not include (2,1) because (1,2) already was enumerated. The same applies to (3,1) and (3,2).

So to compute the probability of a Natural 21 in Blackjack, we can do this:
```{r}
aces <- paste("Ace", suits)

facecard <- c("King", "Queen", "Jack", "Ten")
facecard <- expand.grid(number = facecard, suit = suits)
facecard <- paste(facecard$number, facecard$suit)

hands <- combinations(52, 2, v = deck)
mean(hands[,1] %in% aces & hands[,2] %in% facecard)
```

In the last line, we assume the Ace comes first. This is only because we know the way combination enumerates possibilities and it will list this case first. But to be safe, we could have written this and produced the same answer:
```{r}
mean((hands[,1] %in% aces & hands[,2] %in% facecard) |
       (hands[,2] %in% aces & hands[,1] %in% facecard))
```

### 13.6.1 Monte Carlo example
Instead of using combinations to deduce the exact probability of a Natural 21, we can use a Monte Carlo to estimate this probability. 

In this case, we draw two cards over and over and keep track of how many 21s we get. We can use the function sample to draw two cards without replacements:
```{r}
hand <- sample(deck, 2)
hand
```

And then check if one card is an Ace and the other a face card or a 10. Going forward, we include 10 when we say face card. Now we need to check both possibilities:
```{r}
(hands[1] %in% aces & hands[2] %in% facecard) | 
  (hands[2] %in% aces & hands[1] %in% facecard)
```
If we repeat this 10,000 times, we get a very good approximation of the probability of a Natural 21.

Let’s start by writing a function that draws a hand and returns TRUE if we get a 21. The function does not need any arguments because it uses objects defined in the global environment.
```{r}
blackjack <- function(){
   hand <- sample(deck, 2)
  (hand[1] %in% aces & hand[2] %in% facecard) | 
    (hand[2] %in% aces & hand[1] %in% facecard)
}
```

Here we do have to check both possibilities: Ace first or Ace second because we are not using the `combinations` function. The function returns `TRUE` if we get a 21 and `FALSE` otherwise:
```{r}
blackjack()
```

Now we can play this game, say, 10,000 times:
```{r}
B <- 10000
results <- replicate(B, blackjack())
mean(results)
```

## 13.7 Examples
We describe two discrete probability popular examples: the Monty Hall problem and the birthday problem.

### 13.7.1 Monty Hall problem
We can use probability to show that if you stick with the original door choice, your chances of winning a prize remain 1 in 3. However, if you switch to the other door, your chances of winning double to 2 in 3! -> counterintuitive. 

Let’s start with the stick strategy:
```{r}
B <- 10000
monty_hall <- function(strategy){
  doors <- as.character(1:3)
  prize <- sample(c("car", "goat", "goat"))
  prize_door <- doors[prize == "car"]
  my_pick  <- sample(doors, 1)
  show <- sample(doors[!doors %in% c(my_pick, prize_door)],1)
  stick <- my_pick
  stick == prize_door
  switch <- doors[!doors%in%c(my_pick, show)]
  choice <- ifelse(strategy == "stick", stick, switch)
  choice == prize_door
}
stick <- replicate(B, monty_hall("stick"))
mean(stick)
switch <- replicate(B, monty_hall("switch"))
mean(switch)
```
we note that the lines starting with `my_pick` and `show` have no influence on the last logical operation when we stick to our original choice anyway.

This helps us gain some insight by showing that we are removing a door, `show`, that is definitely not a winner from our choices. 

We also see that unless we get it right when we first pick, you win: 1 - 1/3 = 2/3.

### 13.7.2 Birthday problem
Suppose you are with randomly selected group of 50 people who have the chance that at least two people have the same birthday. 

Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29. This actually doesn’t change the answer much.

First, note that birthdays can be represented as numbers between 1 and 365, so a sample of 50 birthdays can be obtained like this:
```{r}
n <- 50
bdays <- sample(1:365, n, replace = TRUE)
```

To check if in this particular set of 50 people we have at least two with the same birthday, we can use the function `duplicated`, which returns `TRUE` whenever an element of a vector is a duplicate. Here is an example:
```{r}
duplicated(c(1,2,3,1,4,3,5))
```

The second time 1 and 3 appear, we get a TRUE. So to check if two birthdays were the same, we simply use the any and duplicated functions like this:
```{r}
any(duplicated(bdays))
```
In this case, we see that it did happen. At least two people had the same birthday.

To estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 50 birthdays over and over:
```{r}
B <- 10000
same_birthday <- function(n){
  bdays <- sample(1:365, n, replace=TRUE)
  any(duplicated(bdays))
}
results <- replicate(B, same_birthday(50))
mean(results)
```

Say we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?

Let’s create a look-up table. We can quickly create a function to compute this for any group size:
```{r}
compute_prob <- function(n, B=10000){
  results <- replicate(B, same_birthday(n))
  mean(results)
}
```

Using the function `sapply`, we can perform element-wise operations on any function:
```{r}
n <- seq(1,60)
prob <- sapply(n, compute_prob)
```

We can now make a plot of the estimated probabilities of two people having the same birthday in a group of size n:
```{r}
library(tidyverse)
prob <- sapply(n, compute_prob)
qplot(n, prob)
```

Now let’s compute the exact probabilities rather than use Monte Carlo approximations. Not only do we get the exact answer using math, but the computations are much faster since we don’t have to generate experiments.

We can write a function that does this for any number:
```{r}
exact_prob <- function(n){
  prob_unique <- seq(365,365-n+1)/365 
  1 - prod( prob_unique)
}
eprob <- sapply(n, exact_prob)
qplot(n, prob) + geom_line(aes(n, eprob), col = "red")
```
This plot shows that the Monte Carlo simulation provided a very good estimate of the exact probability.

## 13.8 Infinity in practice
The theory described here requires repeating experiments over and over forever. = impossible
We know that the larger B, the better the approximation. (Monte Carlo experiment)

One practical approach we will describe here is to check for the stability of the estimate. The following is an example with the birthday problem for a group of 25 people.
```{r}
B <- 10^seq(1, 5, len = 100)
compute_prob <- function(B, n=25){
  same_day <- replicate(B, same_birthday(n))
  mean(same_day)
}
prob <- sapply(B, compute_prob)
qplot(log10(B), prob, geom = "line")
```
In this plot, we can see that the values start to stabilize (that is, they vary less than .01) around 1000. Note that the exact probability, which we know in this case, is 0.569.

## 13.9 Exercises
1. One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?
```{r}
balls <- rep(c("cyan","magenta","yellow"), times =c(3,5,7))
B <- 10000
events <- replicate(B, sample(balls, 1))
tab <- table(events)
prop.table(tab)
```

2. What is the probability that the ball will not be cyan?
```{r}
without_cyan <- 0.3269 + 0.4616
without_cyan
```

3. Instead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling **without** replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?
```{r}
events <- sample(balls, B,replace = FALSE)
```

4. Now repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling **with** replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?
```{r}

```

5. Two events \(A\) and \(B\) are independent if \(\mbox{Pr}(A \mbox{ and } B) = \mbox{Pr}(A) P(B)\). Under which situation are the draws independent?
```{r}

```


6. Say you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?
```{r}

```

7. If you roll a 6-sided die six times, what is the probability of not seeing a 6?
```{r}

```

8. Two teams, say the Celtics and the Cavs, are playing a seven game series. The Cavs are a better team and have a 60% chance of winning each game. What is the probability that the Celtics win **at least** one game?
```{r}

```

9. Create a Monte Carlo simulation to confirm your answer to the previous problem. Use `B <- 10000` simulations. Hint: use the following code to generate the results of the first four games:
```{r}
celtic_wins <- sample(c(0,1), 4, replace = TRUE, prob = c(0.6, 0.4))
```
The Celtics must win one of these 4 games.

10. Two teams, say the Cavs and the Warriors, are playing a seven game championship series. The first to win four games, therefore, wins the series. The teams are equally good so they each have a 50-50 chance of winning each game. If the Cavs lose the first game, what is the probability that they win the series?

11. Confirm the results of the previous question with a Monte Carlo simulation.

12. Two teams, \(A\) and \(B\), are playing a seven game series. Team \(A\) is better than team \(B\) and has a \(p>0.5\) chance of winning each game. Given a value \(p\), the probability of winning the series for the underdog team \(B\) can be computed with the following function based on a Monte Carlo simulation:
```{r}
prob_win <- function(p){
  B <- 10000
  result <- replicate(B, {
    b_win <- sample(c(1,0), 7, replace = TRUE, prob = c(1-p, p))
    sum(b_win)>=4
  })
  mean(result)
}
```
Use the function `sapply` to compute the probability, call it `Pr`, of winning for `p <- seq(0.5, 0.95, 0.025)`. Then plot the result.

13. Repeat the exercise above, but now keep the probability fixed at `p <- 0.75` and compute the probability for different series lengths: best of 1 game, 3 games, 5 games,… Specifically,` N <- seq(1, 25, 2)`. Hint: use this function:
```{r}
prob_win <- function(N, p=0.75){
  B <- 10000
  result <- replicate(B, {
    b_win <- sample(c(1,0), N, replace = TRUE, prob = c(1-p, p))
    sum(b_win)>=(N+1)/2
  })
  mean(result)
}
```






