---
title: "20191113"
output: html_notebook
---

## 14.7 Central Limit Theorem
Central Limit Theorem(CLT): when the sample size is large, the probability distribution of the sum of the independent draws is approximately normal.

- the distribution of a list of numbers = normal distribution
   -> need to describe: average and standard deviation
- the probability distribution of random variable = normal distribution
   -> need to describe: average(expected value) and sd(standard error) 

We previously ran this Monte Carlo simulation:
```{r}
n <- 1000
B <- 10000
roulette_winnings <- function(n){
  X <- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S <- replicate(B, roulette_winnings(n))
```

The Central Limit Theorem (CLT) tells us that the sum $S$ is approximated by a normal distribution. Using the formulas above, we know that the expected value and standard error are:
```{r}
n * (20-18)/38 
sqrt(n) * 2 * sqrt(90)/19 
```

The theoretical values above match those obtained with the Monte Carlo simulation:
```{r}
mean(S)
sd(S)
```

Using the CLT, we can skip the Monte Carlo simulation and instead compute the probability of the casino losing money using this approximation:
```{r}
mu <- n * (20-18)/38
se <-  sqrt(n) * 2 * sqrt(90)/19 
pnorm(0, mu, se)
```

which is also in very good agreement with our Monte Carlo result:
```{r}
mean(S < 0)
```

### 14.7.1 How large is large in the Central Limit Theorem?
The CLT works when the number of draws is large.
Note, for example, that when the probability of success is very small, we need much larger sample sizes.

The Poisson distribution is more appropriate when the sum is not well approximated by a normal distribution even with the very large sample size.

You can examine the properties of the Poisson distribution using `dpois` and `ppois`. You can generate random variables following this distribution with `rpois`.

## 14.8 Statistical properties of averages
There are several useful mathematical results that we used above and often employ when working with data. We list them below.

1. The expected value of the sum of random variables is the sum of each random variable’s expected value. We can write it like this:
$$
E[X_1 +X_2+ ... + X_n] = E[X_1] +E[X_2]+ ... + E[X_n]
$$
If the $X$ are independent draws from the urn, then they all have the same expected value. Let’s call it $μ$ and thus:

$$
E[X_1 +X_2+ ... + X_n] = nμ 
$$
which is another way of writing the result we show above for the sum of draws.

2. The expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable. This is easier to explain with symbols:
$$
E[aX]=a×E[X]
$$
If we change the units of a random variable, say from dollars to cents, the expectation should change in the same way. 

The expected value of the average of independent draws from the same urn is the expected value of the urn, call it $μ$ again: 
$$
E[(X_1 +X_2+ ... + X_n)/n] = E[X_1 +X_2+ ... + X_n]/n = nμ/n=μ
$$

3. The square of the standard error of the sum of **independent** random variables is the sum of the square of the standard error of each random variable. This one is easier to understand in math form:
$$
SE[X_1 +X_2+ ... + X_n] = \sqrt{SE[X_1]^2 +SE[X_2]^2+ ... + SE[X_n]^2}
$$
The square of the standard error = *variance*

4. The standard error of a non-random constant times a random variable is the non-random constant times the random variable’s standard error. As with the expectation:
$$
SE[aX]=a×SE[X]
$$

A consequence of 3 and 4 is that the standard error of the average of independent draws from the same urn is the standard deviation of the urn divided by the square root of $n$ (the number of draws), call it $σ$:
$$
SE[(X_1 +X_2+ ... + X_n)/n] = SE[X_1 +X_2+ ... + X_n]/n\\
=\sqrt{SE[X_1]^2 +SE[X_2]^2+ ⋯+ SE[X_n]^2}/n\\
=\sqrt{σ^2+σ^2+⋯+σ^2/}n\\
=\sqrt{nσ^2}/n\\
=σ/\sqrt{n}
$$

5. If $X$ is a normally distributed random variable, then if  
$a$ and $b$ are non-random constants, $aX+b$ is also a normally distributed random variable. All we are doing is changing the units of the random variable by multiplying by $a$, then shifting the center by $b$.

## 14.9 Law of large numbers
The standard error of the average becomes smaller and smaller as $n$ grows larger.
When $n$ is very large, then the standard error is practically 0 and the average of the draws converges to average of the urn.

## 14.10 Exercises
1. In American Roulette you can also bet on green. There are 18 reds, 18 blacks and 2 greens (0 and 00). What are the chances the green comes out?

2. The payout for winning on green is $17 dollars. This means that if you bet a dollar and it lands on green, you get $17. Create a sampling model using sample to simulate the random variable $X$ for your winnings. Hint: see the example below for how it should look like when betting on red.

3. Compute the expected value of $X$.

4. Compute the standard error of $X$.

5. Now create a random variable $S$ that is the sum of your winnings after betting on green 1000 times. Hint: change the argument `size` and `replace` in your answer to question 2. Start your code by setting the seed to 1 with `set.seed(1)`.

6. What is the expected value of $S$?

7. What is the standard error of $S$?

8. What is the probability that you end up winning money? Hint: use the CLT.

9. Create a Monte Carlo simulation that generates 1,000 outcomes of $S$. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with `set.seed(1)`.

10. Now check your answer to 8 using the Monte Carlo result.

11. The Monte Carlo result and the CLT approximation are close, but not that close. What could account for this? 

12. Now create a random variable $Y$ that is your average winnings per bet after playing off your winnings after betting on green 1,000 times.

13. Wht is the expected value of $Y$?

14. What is the standar error of $Y$?

15. What is the probability that you end up with winnings per game that are positive? Hint: use the CLT.

16. Create a Monte Carlo simulation that generates 2,500 outcomes of $Y$. Compute the average and standard deviation of the resulting list to confirm the results of 6 and 7. Start your code by setting the seed to 1 with `set.seed(1)`.

17. Now check your answer to 8 using the Monte Carlo result.

18. The Monte Carlo result and the CLT approximation are now much closer. What could account for this?


## 14.11 Case study: The Big Short

## 14.11.1 Interest rates explained with chance model
Suppose your bank will give out 1,000 loans for $180,000 this year. Also, after adding up all costs, suppose your bank loses $200,000 per foreclosure. For simplicity, we assume this includes all operational costs. A sampling model for this scenario can be coded like this:
```{r}
n <- 1000
loss_per_foreclosure <- -200000
p <- 0.02 
defaults <- sample( c(0,1), n, prob=c(1-p, p), replace = TRUE)
sum(defaults * loss_per_foreclosure)
```

Note that the total loss defined by the final sum is a random variable. Every time you run the above code, you get a different answer. We can easily construct a Monte Carlo simulation to get an idea of the distribution of this random variable.
```{r}
B <- 10000
losses <- replicate(B, {
    defaults <- sample( c(0,1), n, prob=c(1-p, p), replace = TRUE) 
  sum(defaults * loss_per_foreclosure)
})
```

We don’t really need a Monte Carlo simulation though. Using what we have learned, the CLT tells us that because our losses are a sum of independent draws, its distribution is approximately normal with expected value and standard errors given by:
```{r}
n*(p*loss_per_foreclosure + (1-p)*0)
sqrt(n)*abs(loss_per_foreclosure)*sqrt(p*(1-p))
```

We can now set an interest rate to guarantee that, on average, we break even. Basically, we need to add a quantity $x$ to each loan, which in this case are represented by draws, so that the expected value is 0. If we define $l$ to be the loss per foreclosure, we need:
$$
lp+x(1-p)=0
$$

which implies $x$ is
```{r}
- loss_per_foreclosure*p/(1-p)
```
or an interest rate of 0.023.

So let’s say that we want our chances of losing money to be 1 in 100, what does the $x$ quantity need to be now? This one is a bit harder. We want the sum $S$ to have:
$$
Pr(S<0)=0.01
$$
We know that $S$ is approximately normal. The expected value of $S$ is
$$
E[S]=\{lp+x(1-p)\}n
$$
witn $n$ the number of draws, which in this case represents loans. The standard error is
$$
SD[S]=|x-l|\sqrt{np(1-p)}
$$
Because $x$ is positive and $l$ negative $|x-l|=x-l$. 

If $Pr(S<0)=0.01$ then
$$
Pr(\dfrac{S-E[S]}{SE[S]}<\dfrac{E[S]}{SE[S]})
$$

$E[S]$ and $SE[S]$ are the expected value and standard error of $S$.

The left is a standard normal random variable ($Z$)

Now we fill in the blanks with the actual formula for expected value and standard error:
$$
Pr(Z<\dfrac{-\{lp+x(1-p)\}n}{(x-l)\sqrt{np(1-p)}}) = 0.01
$$

Now because the Z is a normal random with expected value 0 and standard error 1, it means that the quantity on the right side of the < sign must be equal to:
```{r}
qnorm(0.01)
```

for the equation to hold true. Remember that  
$z$=`qnorm(0.01)` gives us the value of $z$ for which:
$$
Pr(Z≤z)=0.01
$$

So this means that the right side of the complicated equation must be  
$z$=`qnorm(0.01)`.
$$
\dfrac{-\{lp+x(1-p)\}n}{(x-l)\sqrt{np(1-p)}} = z
$$

The trick works because we end up with an expression containing $x$ that we know has to be equal to a known quantity $z$. Solving for $x$ is now simply algebra:
$$
x=-l\dfrac{np-z\sqrt{np(1-p)}}{n(l-p)+z\sqrt{np(1-p)}}
$$
  
which is:
```{r}
l <- loss_per_foreclosure
z <- qnorm(0.01)
x <- -l*( n*p - z*sqrt(n*p*(1-p)))/ ( n*(1-p) + z*sqrt(n*p*(1-p)))
x
```

Our interest rate now goes up to 0.035. This is still a very competitive interest rate. By choosing this interest rate, we now have an expected profit per loan of:
```{r}
loss_per_foreclosure*p + x*(1-p)
```

which is a total expected profit of about:
```{r}
n*(loss_per_foreclosure*p + x*(1-p)) 
```

We can run a Monte Carlo simulation to double check our theoretical approximations:
```{r}
B <- 100000
profit <- replicate(B, {
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-p, p), replace = TRUE) 
    sum(draws)
})
mean(profit)
mean(profit<0)
```

## 14.11.2 The Big Short
He claims that even if the default rate is twice as high, say 4%, if we set the rate just a bit higher than this value:
```{r}
p <- 0.04
r <- (- loss_per_foreclosure*p/(1-p)) / 180000
r
```

we will profit. At 5%, we are guaranteed a positive expected value of:
```{r}
r <- 0.05
x <- r*180000
loss_per_foreclosure*p + x * (1-p)
```

and can minimize our chances of losing money by simply increasing $n$ since:
$$
Pr(S<0)=Pr(Z<-\dfrac{E[S]}{SE[S]})
$$
with $S$ a standard normal random variable as shown earlier.

If we define $μ$ and $σ$ to be the expected value and standard deviation of the urn, respectively (that is of a single loan), using the formulas above we have
: $E[S]=nμ$ and $SE[S]=\sqrt{n}σ$. So if we define $z$=`qnorm(0.01)`, we have:
$$
-\dfrac{nμ}{\sqrt{n}σ} = -\dfrac{\sqrt{n}μ}{σ}=z
$$
 
which implies that if we let:
$$
n≥z^2σ^2/μ^2
$$

With $x$ fixed, now we can ask what $n$ do we need for the probability to be 0.01? In our example, if we give out:
```{r}
z <- qnorm(0.01)
n <- ceiling((z^2*(x-l)^2*p*(1-p))/(l*p + x*(1-p))^2)
n
```

loans, the probability of losing is about 0.01 and we are expected to earn a total of
```{r}
n*(loss_per_foreclosure*p + x * (1-p))
```

dollars! We can confirm this with a Monte Carlo simulation:
```{r}
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-p, p), replace = TRUE) 
    sum(draws)
})
mean(profit)
```

Your colleague’s scheme was mainly based on this mathematical formula:
$$
SE[(X_1+X_2+⋯X_n)/n]=σ/\sqrt{n}
$$

In the case of averaging the same event over and over, an extreme example of events that are not independent, we get a standard error that is$\sqrt{n}$ times bigger:
$$
SE[(X_1+X_2+⋯X_n)/n]=SE[nX_1/n]=σ>σ/\sqrt{n}
$$

To construct a more realistic simulation than the original one your colleague ran, let’s assume there is a global event that affects everybody with high-risk mortgages and changes their probability. We will assume that with 50-50 chance, all the probabilities go up or down slightly to somewhere between 0.03 and 0.05. But it happens to everybody at once, not just one person. These draws are no longer independent.
```{r}
p <- 0.04
x <- 0.05*180000
profit <- replicate(B, {
    new_p <- 0.04 + sample(seq(-0.01, 0.01, length = 100), 1)
    draws <- sample( c(x, loss_per_foreclosure), n, 
                        prob=c(1-new_p, new_p), replace = TRUE) 
    sum(draws)
})
```

Note that our expected profit is still large:
```{r}
mean(profit)
```

However, the probability of the bank having negative earnings shoots up to:
```{r}
mean(profit<0)
```

Even scarier is that the probability of losing more than 10 million dollars is:
```{r}
mean(profit < -10000000)
```

To understand how this happens look at the distribution:
```{r}
data.frame(profit_in_millions=profit/10^6) %>% 
  ggplot(aes(profit_in_millions)) + 
  geom_histogram(color="black", binwidth = 5)
```


## 14.12 Exercises
1. Create a random variable $S$ with the earnings of your bank if you give out 10,000 loans, the default rate is 0.3, and you lose $200,000 in each foreclosure. Hint: use the code we showed in the previous section, but change the parameters.

2. Run a Monte Carlo simulation with 10,000 outcomes for $S$. Make a histogram of the results.

3. What is the expected value of $S$?

4. What is the standard error of $S$?

5. Suppose we give out loans for $180,000. What should the interest rate be so that our expected value is 0?

6. (Harder) What should the interest rate be so that the chance of losing money is 1 in 20? In math notation, what should the interest rate be so that $Pr(S<0)=0.05?$

7. If the bank wants to minimize the probabilities of losing money, which of the following does not make interest rates go up?



